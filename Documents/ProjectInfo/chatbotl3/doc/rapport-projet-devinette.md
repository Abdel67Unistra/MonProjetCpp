# Rapport de Projet : Jeu de Devinettes avec API LLM

**Auteur**: Cheriet Abdelmalek  
**Date**: Mai 2025  
**Version**: 2.0

## Table des Mati√®res

1. [Introduction](#introduction)
2. [Pr√©sentation du Projet](#pr√©sentation-du-projet)
   - [Objectifs](#objectifs)
   - [Fonctionnalit√©s Impl√©ment√©es](#fonctionnalit√©s-impl√©ment√©es)
3. [Architecture du Syst√®me](#architecture-du-syst√®me)
   - [Vue d'ensemble](#vue-densemble)
   - [Diagramme UML](#diagramme-uml)
4. [Impl√©mentation D√©taill√©e](#impl√©mentation-d√©taill√©e)
   - [Classe Chatbot](#classe-chatbot)
   - [Classe Devinette](#classe-devinette)
   - [Communication avec l'API LLM](#communication-avec-lapi-llm)
5. [Modes de Jeu](#modes-de-jeu)
   - [Mode LLM-Pense](#mode-llm-pense)
   - [Mode Utilisateur-Pense](#mode-utilisateur-pense)
6. [Gestion des Cas d'Erreur](#gestion-des-cas-derreur)
   - [Erreurs R√©seau](#erreurs-r√©seau)
   - [Erreurs de Requ√™te](#erreurs-de-requ√™te)
   - [Erreurs de R√©ponse](#erreurs-de-r√©ponse)
7. [Tests et Qualit√© du Code](#tests-et-qualit√©-du-code)
   - [Strat√©gie de Tests](#strat√©gie-de-tests)
   - [Gestion de la Qualit√©](#gestion-de-la-qualit√©)
   - [Automatisation des Tests](#automatisation-des-tests)
8. [Optimisations](#optimisations)
   - [Promptes Optimis√©s](#promptes-optimis√©s)
   - [Gestion de l'Historique](#gestion-de-lhistorique)
   - [Formatage des R√©ponses](#formatage-des-r√©ponses)
9. [Guide d'Utilisation](#guide-dutilisation)
   - [Pr√©requis](#pr√©requis)
   - [Compilation](#compilation)
   - [Ex√©cution](#ex√©cution)
10. [Conclusion et Perspectives](#conclusion-et-perspectives)
11. [Annexes](#annexes)
    - [Annexe A: Prompts Utilis√©s](#annexe-a-prompts-utilis√©s)
    - [Annexe B: Journal de D√©veloppement](#annexe-b-journal-de-d√©veloppement)
    - [Annexe C: R√©f√©rences et Ressources](#annexe-c-r√©f√©rences-et-ressources)

## Introduction

Ce projet impl√©mente un jeu de devinettes interactif en C++ utilisant un mod√®le de langage de grande taille (LLM) via une API REST. Le jeu permet deux modes d'interaction distincts : soit le mod√®le LLM pense √† un mot et l'utilisateur tente de le deviner par des questions oui/non, soit l'utilisateur pense √† un mot et le LLM essaie de le deviner en posant des questions strat√©giques.

L'impl√©mentation repose sur une architecture modulaire, avec une s√©paration claire entre la logique de communication avec l'API et la gestion du jeu lui-m√™me. Cette approche garantit une flexibilit√© maximale et facilite la maintenance et les √©volutions futures du projet.

## Pr√©sentation du Projet

### Objectifs

Le projet vise √† atteindre les objectifs suivants :

1. **Cr√©er une interface de jeu interactive** entre l'utilisateur et un mod√®le LLM
2. **Impl√©menter deux modes de jeu distincts** (LLM-Pense et Utilisateur-Pense)
3. **√âtablir une communication robuste** avec l'API du serveur LLM
4. **G√©rer efficacement les erreurs et les cas limites** pour assurer une exp√©rience utilisateur fluide
5. **D√©montrer une utilisation avanc√©e des LLMs** √† travers une application ludique en C++

### Fonctionnalit√©s Impl√©ment√©es

Le jeu de devinettes offre les fonctionnalit√©s suivantes :

- **Structure modulaire** avec deux classes principales : `Chatbot` et `Devinette`
- **Communication HTTP s√©curis√©e** via la biblioth√®que CPR (C++ Requests)
- **Traitement JSON avanc√©** gr√¢ce √† la biblioth√®que nlohmann/json
- **Deux modes de jeu complets** :
  - Mode o√π le LLM choisit un mot et l'utilisateur doit le deviner
  - Mode o√π l'utilisateur pense √† un mot et le LLM tente de le deviner
- **Gestion robuste des erreurs** avec messages explicites et strat√©gies de r√©cup√©ration
- **Formatage intelligent des r√©ponses** pour garantir une exp√©rience utilisateur coh√©rente
- **Syst√®me de session** avec identifiants uniques pour chaque partie
- **Mode verbeux** pour le d√©bogage et le d√©veloppement

## Architecture du Syst√®me

### Vue d'ensemble

L'architecture du syst√®me repose sur une approche modulaire √† deux niveaux :

1. **Couche de Communication (Classe Chatbot)** :
   - G√®re toutes les interactions avec l'API du serveur LLM
   - Encapsule les d√©tails de la communication HTTP et du traitement des r√©ponses
   - Maintient l'√©tat de la session et l'historique des conversations

2. **Couche de Logique de Jeu (Classe Devinette)** :
   - Impl√©mente les r√®gles du jeu et la logique m√©tier
   - G√®re l'interface utilisateur et les interactions
   - Utilise la classe Chatbot pour communiquer avec le LLM

Cette s√©paration des pr√©occupations garantit une base de code maintenable et extensible.

### Diagramme UML

```
+-------------------+       +-------------------+
|     Chatbot       |<------|     Devinette     |
+-------------------+       +-------------------+
| - api_key: string |       | - chatbot: Chatbot|
| - model: string   |       | - game_mode: int  |
| - server_url: string|     | - debug_mode: bool|
| - session_id: string|     +-------------------+
| - context: string |       | + start(): void   |
| - last_error: string|     | + playerGuessing()|
| - rng: mt19937    |       | + aiGuessing()    |
| - history: vector<string>| | + showMenu()     |
| - message_history: json|  | + setGameMode()   |
+-------------------+       | + testConnection()|
| + Chatbot(...)    |       | + displayHelp()   |
| + testConnection()|       | + toggleDebugMode()|
| + reset(): void   |       +-------------------+
| + ask(): string   |
| + thinkOfWord()   |
| + setUserThinking()|
| + guess(): string |
| - sendRequest()   |
| - escapeString()  |
| - formatResponse()|
+-------------------+
```

## Impl√©mentation D√©taill√©e

### Classe Chatbot

La classe `Chatbot` est le c≈ìur du syst√®me de communication avec l'API LLM. Elle encapsule toute la logique n√©cessaire pour envoyer des requ√™tes, interpr√©ter les r√©ponses et maintenir le contexte de la conversation.

```cpp
class Chatbot {
private:
    std::string api_key;
    std::string model;
    std::string server_url;
    std::string session_id;
    std::string context;
    std::string last_error;
    std::mt19937 rng;
    std::vector<std::string> history;
    nlohmann::json message_history;

    // M√©thodes priv√©es
    std::string sendRequest(const std::string& prompt);
    std::string escapeString(const std::string& input);
    std::string formatResponse(const std::string& response);

public:
    // Constructeur
    Chatbot(const std::string& api_key, const std::string& model, const std::string& server_url);
    
    // M√©thodes principales
    bool testConnection();
    void reset();
    std::string ask(const std::string& question);
    void thinkOfWord();
    void setUserThinking();
    std::string guess(const std::string& last_answer);
};
```

#### M√©thodes cl√©s de la classe Chatbot

- **`Chatbot(api_key, model, server_url)`** : Initialise une nouvelle instance avec les param√®tres de connexion.
- **`testConnection()`** : V√©rifie la connexion √† l'API en envoyant une requ√™te de test.
- **`reset()`** : R√©initialise le contexte et l'historique, g√©n√©rant une nouvelle session.
- **`ask(question)`** : Envoie une question au LLM et retourne sa r√©ponse.
- **`thinkOfWord()`** : Configure le LLM pour choisir un mot √† deviner (mode LLM-Pense).
- **`setUserThinking()`** : Configure le LLM pour qu'il devine le mot de l'utilisateur (mode Utilisateur-Pense).
- **`guess(last_answer)`** : G√©n√®re une nouvelle question ou suggestion bas√©e sur la r√©ponse pr√©c√©dente.

#### M√©thodes priv√©es importantes

- **`sendRequest(prompt)`** : M√©thode centrale qui g√®re l'envoi de requ√™tes HTTP √† l'API et le traitement des r√©ponses.
- **`formatResponse(response)`** : Nettoie et standardise les r√©ponses du LLM pour garantir une exp√©rience coh√©rente.
- **`escapeString(input)`** : √âchappe les caract√®res sp√©ciaux pour le traitement JSON.

### Classe Devinette

La classe `Devinette` impl√©mente la logique du jeu et g√®re l'interface utilisateur. Elle utilise une instance de `Chatbot` pour communiquer avec le LLM.

```cpp
class Devinette {
private:
    Chatbot chatbot;
    int game_mode;
    bool debug_mode;
    
    // M√©thodes priv√©es
    bool isValidQuestion(const std::string& question);
    int getIntInput(int min, int max);

public:
    // Constructeur
    Devinette(const std::string& api_key, const std::string& model, const std::string& server_url);
    
    // M√©thodes principales
    void start();
    void showMenu();
    void playerGuessingRound();
    void aiGuessingRound();
    void setGameMode(int mode);
    bool testConnection();
    void displayHelp();
    void toggleDebugMode();
};
```

#### M√©thodes cl√©s de la classe Devinette

- **`start()`** : Point d'entr√©e principal du jeu, affiche le menu et g√®re la boucle principale.
- **`showMenu()`** : Affiche le menu principal et traite les choix de l'utilisateur.
- **`playerGuessingRound()`** : Impl√©mente une partie o√π l'utilisateur devine le mot du LLM.
- **`aiGuessingRound()`** : Impl√©mente une partie o√π le LLM devine le mot de l'utilisateur.
- **`testConnection()`** : V√©rifie la connexion √† l'API avant de commencer le jeu.
- **`displayHelp()`** : Affiche les instructions et r√®gles du jeu.
- **`toggleDebugMode()`** : Active/d√©sactive le mode de d√©bogage pour afficher des informations suppl√©mentaires.

### Communication avec l'API LLM

La communication avec l'API LLM est r√©alis√©e √† travers la biblioth√®que CPR (C++ Requests), qui offre une interface moderne et intuitive pour les requ√™tes HTTP. Le projet utilise les fonctionnalit√©s suivantes de CPR :

- **Requ√™tes POST** avec corps JSON pour envoyer des prompts au LLM
- **Headers d'authentification** pour l'API key via Bearer token
- **Gestion des timeout** pour √©viter les blocages en cas de probl√®mes de r√©seau
- **Mode verbeux** pour le d√©bogage des requ√™tes et r√©ponses

Exemple d'impl√©mentation d'une requ√™te √† l'API dans la m√©thode `sendRequest()` :

```cpp
cpr::Response r = cpr::Post(
    cpr::Url{server_url},
    cpr::Header{
        {"Content-Type", "application/json"},
        {"Accept", "application/json"},
        {"Authorization", "Bearer " + api_key}
    },
    cpr::Body{parameters.dump()},
    cpr::Timeout{60000}, // 60 secondes
    cpr::Verbose{} // Mode verbeux pour le d√©bogage
);
```

Le traitement des r√©ponses est effectu√© √† l'aide de la biblioth√®que nlohmann/json, qui permet de manipuler facilement les structures JSON :

```cpp
json response = json::parse(r.text);
if (response.contains("choices") && !response["choices"].empty()) {
    std::string text = response["choices"][0]["message"]["content"].get<std::string>();
    return formatResponse(text);
}
```

## Modes de Jeu

### Mode LLM-Pense

Dans ce mode, le LLM choisit secr√®tement un mot et l'utilisateur doit le deviner en posant des questions auxquelles le LLM r√©pond par "oui" ou "non".

#### Initialisation

```cpp
void Chatbot::thinkOfWord() {
    context = "Tu es un assistant pour un jeu de devinettes. Choisis un mot simple du quotidien (nom commun concret) et r√©ponds uniquement par 'oui', 'non' ou 'Bravo, tu as trouv√© !' aux questions pos√©es.";
    
    // R√©initialiser l'historique des messages
    message_history.clear();
    
    // Ajouter le message syst√®me
    message_history.push_back({
        {"role", "system"},
        {"content", context}
    });
    
    // Ajouter la demande de choisir un mot
    message_history.push_back({
        {"role", "user"},
        {"content", "Choisis un mot et r√©ponds simplement 'J'ai choisi un mot.'"}
    });
    
    // Envoyer la requ√™te et traiter la r√©ponse...
}
```

#### D√©roulement du jeu

1. L'utilisateur pose une question par tour.
2. La question est envoy√©e au LLM via la m√©thode `ask()`.
3. Le LLM r√©pond par "oui", "non" ou indique que l'utilisateur a trouv√© le mot.
4. Le jeu continue jusqu'√† ce que l'utilisateur trouve le mot ou abandonne.

### Mode Utilisateur-Pense

Dans ce mode, l'utilisateur pense √† un mot et le LLM tente de le deviner en posant des questions strat√©giques auxquelles l'utilisateur r√©pond par "oui" ou "non".

#### Initialisation

```cpp
void Chatbot::setUserThinking() {
    context = "L'utilisateur a choisi un mot. Pose des questions oui/non strat√©giques pour deviner le mot, ou propose une r√©ponse si tu penses l'avoir trouv√©. Ne r√©p√®te pas les questions d√©j√† pos√©es. Assure-toi que chaque nouvelle question r√©duit efficacement l'ensemble des possibilit√©s.";
    
    // R√©initialiser l'historique des messages
    message_history.clear();
    
    // Ajouter le message syst√®me
    message_history.push_back({
        {"role", "system"},
        {"content", context}
    });
    
    history.clear();
}
```

#### D√©roulement du jeu

1. Le LLM pose une question via la m√©thode `guess()`.
2. L'utilisateur r√©pond par "oui" ou "non".
3. La r√©ponse est envoy√©e au LLM qui formule une nouvelle question ou propose une solution.
4. Le jeu continue jusqu'√† ce que le LLM trouve le mot ou abandonne.

## Gestion des Cas d'Erreur

Le projet impl√©mente une gestion robuste des erreurs √† plusieurs niveaux pour garantir une exp√©rience utilisateur fluide m√™me en cas de probl√®mes.

### Erreurs R√©seau

Les erreurs r√©seau (timeout, connexion refus√©e, etc.) sont captur√©es et trait√©es de mani√®re explicite :

```cpp
if (r.error.code == cpr::ErrorCode::OPERATION_TIMEDOUT) {
    last_error = "Erreur: d√©lai d'attente d√©pass√© pour la connexion au serveur.";
    std::cerr << last_error << std::endl;
    return "Erreur: le serveur met trop de temps √† r√©pondre.";
}
```

### Erreurs de Requ√™te

Les codes d'erreur HTTP sont analys√©s pour fournir des messages d'erreur pertinents :

```cpp
if (r.status_code != 200) {
    last_error = "Erreur HTTP " + std::to_string(r.status_code) + ": " + r.text + " - " + r.error.message;
    if (r.status_code == 429) last_error += " (limite de requ√™tes d√©pass√©e)";
    else if (r.status_code == 401) last_error += " (authentification invalide)";
    else if (r.status_code == 0) last_error += " (erreur r√©seau ou serveur inaccessible)";
    std::cerr << last_error << std::endl;
    return "Erreur: impossible de contacter l'API.";
}
```

### Erreurs de R√©ponse

Les r√©ponses invalides ou mal format√©es sont d√©tect√©es et g√©r√©es :

```cpp
try {
    json response = json::parse(r.text);
    if (response.contains("choices") && !response["choices"].empty()) {
        std::string text = response["choices"][0]["message"]["content"].get<std::string>();
        return formatResponse(text);
    }

    last_error = "R√©ponse invalide de l'API: " + r.text;
    std::cerr << last_error << std::endl;
    return "Erreur: r√©ponse invalide.";
} catch (const std::exception& e) {
    last_error = "Erreur de traitement de la r√©ponse: " + std::string(e.what());
    std::cerr << last_error << std::endl;
    return "Erreur: probl√®me lors de la requ√™te.";
}
```

## Tests et Qualit√© du Code

### Strat√©gie de Tests

Pour garantir la qualit√© et la fiabilit√© du projet, une strat√©gie de tests compl√®te a √©t√© mise en place. Cette strat√©gie repose sur plusieurs niveaux de tests :

#### Tests Unitaires

Les tests unitaires v√©rifient le bon fonctionnement des composants individuels du syst√®me :

```cpp
TEST_F(ChatbotTest, InitialisationCorrect) {
    EXPECT_EQ(chatbot->getModel(), "test-model");
    EXPECT_EQ(chatbot->getApiKey(), "test_key");
}

TEST_F(ChatbotTest, HistoriqueInitialVide) {
    const auto& history = chatbot->getHistory();
    EXPECT_TRUE(history.empty());
}

TEST_F(ChatbotTest, ResetEffaceHistorique) {
    chatbot->ask("test question");
    chatbot->reset();
    const auto& history = chatbot->getHistory();
    EXPECT_TRUE(history.empty());
}
```

Ces tests v√©rifient :
- L'initialisation correcte des objets
- La gestion de l'historique des conversations
- Le comportement du formatage des r√©ponses
- La robustesse face aux erreurs r√©seau et API

#### Tests d'Int√©gration

Les tests d'int√©gration v√©rifient les interactions entre les diff√©rents composants du syst√®me :

```cpp
TEST_F(IntegrationTest, ChatbotDevinetteInteraction) {
    Devinette game("test_key", "test-model", "http://localhost:8080");
    EXPECT_EQ(game.getGameState(), GameState::INIT);
    
    // Simulation d'un jeu
    game.preparePlayerGuessingRound();
    EXPECT_EQ(game.getGameState(), GameState::PLAYER_GUESSING);
}
```

Ces tests s'assurent que :
- Les classes `Chatbot` et `Devinette` interagissent correctement
- Les transitions d'√©tat du jeu fonctionnent comme pr√©vu
- Les sc√©narios de jeu complets aboutissent aux r√©sultats attendus

### Gestion de la Qualit√©

Plusieurs pratiques ont √©t√© mises en place pour assurer la qualit√© du code :

- **Compilation sans avertissements** : Le code est compil√© avec les options `-Wall -Wextra` pour d√©tecter les probl√®mes potentiels
- **V√©rification de la m√©moire** : Utilisation de Valgrind pour d√©tecter les fuites de m√©moire
- **Analyse statique** : Utilisation d'outils comme Clang-Tidy pour am√©liorer la qualit√© du code
- **Revue de code** : R√©vision r√©guli√®re du code pour identifier les optimisations possibles

### Automatisation des Tests

Un syst√®me d'automatisation des tests a √©t√© mis en place via CMake, permettant d'ex√©cuter facilement l'ensemble des tests :

```bash
cd build
make check
```

Cette commande ex√©cute tous les tests et rapporte les √©ventuels √©checs, facilitant ainsi la d√©tection rapide des r√©gressions.

## Optimisations

### Promptes Optimis√©s

Les prompts utilis√©s pour interagir avec le LLM ont √©t√© soigneusement con√ßus pour maximiser la qualit√© des r√©ponses :

```cpp
// Pour le mode LLM-Pense
context = "Tu es un assistant pour un jeu de devinettes. Choisis un mot simple du quotidien (nom commun concret) et r√©ponds uniquement par 'oui', 'non' ou 'Bravo, tu as trouv√© !' aux questions pos√©es.";

// Pour le mode Utilisateur-Pense
context = "L'utilisateur a choisi un mot. Pose des questions oui/non strat√©giques pour deviner le mot, ou propose une r√©ponse si tu penses l'avoir trouv√©. Ne r√©p√®te pas les questions d√©j√† pos√©es. Assure-toi que chaque nouvelle question r√©duit efficacement l'ensemble des possibilit√©s.";
```

Ces prompts sont pr√©cis et directifs, ce qui aide le LLM √† maintenir le contexte et √† fournir des r√©ponses coh√©rentes.

### Gestion de l'Historique

L'historique des conversations est maintenu de deux mani√®res compl√©mentaires :

1. **Un historique simple** sous forme de vecteur de cha√Ænes de caract√®res pour un affichage facile et un d√©bogage :

```cpp
history.push_back("Utilisateur: " + question + "\nIA: " + response);
```

2. **Un historique structur√©** au format JSON conforme √† l'API pour maintenir le contexte des conversations :

```cpp
message_history.push_back({
    {"role", "user"},
    {"content", prompt}
});

// Puis apr√®s r√©ception de la r√©ponse
message_history.push_back({
    {"role", "assistant"},
    {"content", response}
});
```

Cette double approche permet √† la fois une interaction fluide avec l'API et un suivi facile des conversations pour l'utilisateur.

### Formatage des R√©ponses

Les r√©ponses du LLM sont trait√©es par une fonction de formatage qui garantit une exp√©rience utilisateur coh√©rente :

```cpp
std::string Chatbot::formatResponse(const std::string& response) {
    std::string formatted = response;
    formatted.erase(std::remove(formatted.begin(), formatted.end(), '\r'), formatted.end());
    formatted = formatted.substr(formatted.find_first_not_of(" \n\t"));
    formatted = formatted.substr(0, formatted.find_last_not_of(" \n\t") + 1);

    std::string lower = formatted;
    std::transform(lower.begin(), lower.end(), lower.begin(), ::tolower);
    if (lower == "oui" || lower == "non" || 
        lower.find("bravo") != std::string::npos || 
        lower.find("trouv√©") != std::string::npos ||
        lower.find("correct") != std::string::npos) {
        formatted.erase(std::remove(formatted.begin(), formatted.end(), '\n'), formatted.end());
    }
    return formatted.empty() ? "Erreur: r√©ponse vide." : formatted;
}
```

Cette fonction :
- Supprime les caract√®res de retour chariot
- √âlimine les espaces, tabulations et sauts de ligne superflus
- Simplifie les r√©ponses courtes (oui/non/bravo)
- D√©tecte les r√©ponses vides et les remplace par un message d'erreur

## Guide d'Utilisation

### Pr√©requis

- Compilateur C++ compatible C++17 ou plus r√©cent
- CMake 3.10 ou plus r√©cent
- Biblioth√®ques:
  - CPR (C++ Requests)
  - nlohmann/json
  - Une cl√© API valide pour acc√©der au serveur LLM

### Compilation

1. Cloner le d√©p√¥t et acc√©der au r√©pertoire du projet:

```bash
git clone https://gitlab.univ-lr.fr/[votre-compte]/chatbot-cpp.git
cd chatbot-cpp
```

2. Cr√©er un r√©pertoire de build et g√©n√©rer les fichiers de compilation:

```bash
mkdir build
cd build
cmake ..
```

3. Compiler le projet:

```bash
make
```

### Ex√©cution

1. Ex√©cuter le programme principal:

```bash
./chatbot-cpp [cl√©_API] [mod√®le] [serveur_url]
```

Arguments:
- `cl√©_API`: Votre cl√© API pour le serveur LLM (obligatoire)
- `mod√®le`: Le mod√®le √† utiliser (facultatif, par d√©faut: "mistral-large")
- `serveur_url`: L'URL du serveur LLM (facultatif, par d√©faut: "https://api.mistral.ai/v1/chat/completions")

2. Utiliser le menu interactif pour choisir un mode de jeu et commencer √† jouer.

## Conclusion et Perspectives

Ce projet d√©montre l'int√©gration r√©ussie d'une API LLM dans une application C++ interactive. Le jeu de devinettes offre une exp√©rience utilisateur engageante tout en illustrant les capacit√©s des mod√®les de langage modernes.

Les points forts du projet incluent:
- Une architecture modulaire bien con√ßue avec une s√©paration claire des responsabilit√©s
- Une gestion robuste des erreurs √† tous les niveaux
- Une optimisation des prompts pour obtenir des r√©ponses coh√©rentes et pertinentes
- Une exp√©rience utilisateur fluide malgr√© les contraintes inh√©rentes √† l'interaction avec une API distante

### Perspectives d'am√©lioration

Plusieurs pistes d'am√©lioration pourraient √™tre explor√©es √† l'avenir:

1. **Interface graphique** : D√©velopper une interface graphique avec une biblioth√®que comme Qt ou ImGui
2. **Mode multijoueur** : Permettre √† plusieurs utilisateurs de jouer simultan√©ment
3. **Niveaux de difficult√©** : Ajouter diff√©rents niveaux de difficult√© avec des cat√©gories de mots sp√©cifiques
4. **Statistiques de jeu** : Impl√©menter un syst√®me de suivi des performances pour analyser les strat√©gies
5. **Cache local** : Mettre en cache certaines r√©ponses pour r√©duire la d√©pendance au r√©seau
6. **Support multilingue** : √âtendre le jeu √† d'autres langues en modifiant les prompts

## Gestion de la Fin de Partie et D√©tection de Victoire

### Probl√®me Initial
Le syst√®me ne d√©tectait pas correctement la fin de partie lorsque le joueur trouvait le mot, et continuait √† accepter des questions m√™me apr√®s une victoire.

### Solution Impl√©ment√©e

#### 1. D√©tection de Victoire
- Ajout d'un signal sp√©cial "VICTOIRE" dans la r√©ponse de l'IA
- V√©rification de multiples variations de r√©ponses positives ("bravo", "trouv√©", "gagn√©", "correct")
- Marquage imm√©diat de la fin de partie lors de la d√©tection d'une victoire

#### 2. Gestion de l'√âtat de la Partie
- Impl√©mentation d'une classe `Devinette` pour g√©rer l'√©tat de la partie
- Suivi du nombre de tentatives restantes
- Gestion des messages de victoire et de d√©faite

#### 3. Am√©lioration de l'Interface Utilisateur
- Affichage clair de l'√©tat de la partie
- Messages de victoire et de d√©faite format√©s
- Compteur de tentatives utilis√©es

### Am√©liorations Apport√©es

#### 1. D√©tection de Victoire
```cpp
if (answer == "VICTOIRE") {
    std::cout << "Nombre de tentatives utilis√©es : " << (attempts + 1) << std::endl;
    return;  // Terminer la partie
}
```

#### 2. Gestion des Tentatives
```cpp
while (attempts < maxAttempts) {
    std::cout << "Vous avez " << (maxAttempts - attempts) << " tentatives.\n\n";
    // ... reste du code ...
}
```

#### 3. Messages de Fin de Partie
```cpp
// Victoire
std::cout << "üéâ F√©licitations! Vous avez trouv√© le mot!\n";

// D√©faite
std::cout << "\n‚ùå Game Over ! Vous avez √©puis√© toutes vos tentatives.\n";
std::cout << "Le mot √©tait : " << chatbot.getChosenWord() << std::endl;
```

### Perspectives d'Am√©lioration
1. Ajout de statistiques de jeu
2. Impl√©mentation d'animations de fin
3. Possibilit√© de partager son score
4. Syst√®me de classement des meilleurs scores

## Annexes

### Annexe A: Prompts Utilis√©s

#### Prompt Syst√®me pour le Mode LLM-Pense

```
Tu es un assistant pour un jeu de devinettes. Choisis un mot simple du quotidien (nom commun concret) et r√©ponds uniquement par 'oui', 'non' ou 'Bravo, tu as trouv√© !' aux questions pos√©es.
```

#### Prompt Utilisateur Initial pour le Mode LLM-Pense

```
Choisis un mot et r√©ponds simplement 'J'ai choisi un mot.'
```

#### Prompt Syst√®me pour le Mode Utilisateur-Pense

```
L'utilisateur a choisi un mot. Pose des questions oui/non strat√©giques pour deviner le mot, ou propose une r√©ponse si tu penses l'avoir trouv√©. Ne r√©p√®te pas les questions d√©j√† pos√©es. Assure-toi que chaque nouvelle question r√©duit efficacement l'ensemble des possibilit√©s.
```

#### Prompt pour G√©n√©rer une Question dans le Mode Utilisateur-Pense

```
Bas√© sur les r√©ponses pr√©c√©dentes, pose une nouvelle question oui/non strat√©gique qui n'a pas encore √©t√© pos√©e, ou propose une r√©ponse si tu es s√ªr du mot. R√©ponds uniquement avec la question ou la proposition.
```

### Annexe B: Journal de D√©veloppement

#### Phase 1: Conception et Pr√©paration (Semaine 1)
- Analyse des besoins du projet
- √âtude de l'API LLM et de ses capacit√©s
- Choix des biblioth√®ques (CPR, nlohmann/json)
- Conception de l'architecture du syst√®me

#### Phase 2: Impl√©mentation de Base (Semaine 2)
- Cr√©ation de la classe Chatbot
- Impl√©mentation des requ√™tes HTTP avec CPR
- Mise en place du syst√®me de gestion des erreurs
- Tests de connexion √† l'API

#### Phase 3: Logique de Jeu (Semaine 3)
- D√©veloppement de la classe Devinette
- Impl√©mentation du mode LLM-Pense
- Cr√©ation de l'interface console
- Tests d'int√©gration

#### Phase 4: Finalisation (Semaine 4)
- Impl√©mentation du mode Utilisateur-Pense
- Optimisation des prompts
- Polissage de l'interface utilisateur
- Documentation compl√®te du code
- R√©daction du rapport

### Annexe C: R√©f√©rences et Ressources

#### Biblioth√®ques Utilis√©es
- [CPR (C++ Requests)](https://github.com/libcpr/cpr) - Biblioth√®que pour les requ√™tes HTTP
- [nlohmann/json](https://github.com/nlohmann/json) - Biblioth√®que pour le traitement JSON
- [C++ Standard Library](https://en.cppreference.com/w/cpp/standard_library) - Biblioth√®que standard C++

#### Documentation API
- [API LLM Documentation](https://docs.mistral.ai/) - Documentation officielle de l'API Mistral
- [HTTP Status Codes](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status) - R√©f√©rence des codes d'√©tat HTTP

#### Ressources C++
- [C++ Best Practices](https://github.com/cpp-best-practices/cppbestpractices) - Bonnes pratiques de programmation C++
- [CMake Documentation](https://cmake.org/documentation/) - Documentation officielle de CMake